{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IjrpM7vJgms"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Flatten, Dropout, Dense, UpSampling2D, Reshape\n",
        "from keras.layers import Conv2DTranspose, Activation, BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "%matplotlib inline\n",
        "import matplotlib.pylab as plt \n",
        "from tqdm import tnrange\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import activations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFP3rlmDJkai"
      },
      "source": [
        "img_rows = 224\n",
        "img_cols = 224\n",
        "channel = 3\n",
        "\n",
        "classes = 2\n",
        "\n",
        "depth = 64\n",
        "dropout = 0.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYc-7nd7JkdY"
      },
      "source": [
        "discriminator = Sequential()\n",
        "\n",
        "input_shape = (img_rows, img_cols, channel)\n",
        "\n",
        "discriminator.add(Conv2D(depth*1, 5, strides=2, \n",
        "                         input_shape=input_shape,padding='same'))\n",
        "discriminator.add(LeakyReLU(alpha=0.2))\n",
        "discriminator.add(Dropout(dropout))\n",
        "\n",
        "discriminator.add(Conv2D(depth*2, 5, strides=2, padding='same'))\n",
        "discriminator.add(LeakyReLU(alpha=0.2))\n",
        "discriminator.add(Dropout(dropout))\n",
        "\n",
        "discriminator.add(Conv2D(depth*4, 5, strides=2, padding='same'))\n",
        "discriminator.add(LeakyReLU(alpha=0.2))\n",
        "discriminator.add(Dropout(dropout))\n",
        "\n",
        "discriminator.add(Conv2D(depth*8, 5, strides=1, padding='same'))\n",
        "discriminator.add(LeakyReLU(alpha=0.2))\n",
        "discriminator.add(Dropout(dropout))\n",
        "\n",
        "discriminator.add(Flatten())\n",
        "discriminator.add(Dense(classes + 1))\n",
        "discriminator.add(Activation('softmax'))\n",
        "\n",
        "#discriminator.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vzRm1lnJkgT"
      },
      "source": [
        "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "discriminator_model = Sequential()\n",
        "discriminator_model.add(discriminator)\n",
        "\n",
        "discriminator_model.compile(loss='categorical_crossentropy', \n",
        "                            optimizer=optimizer, \n",
        "                            metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUGwsUoyJkjW"
      },
      "source": [
        "dropout = 0.4\n",
        "depth = 64+64+64+64\n",
        "dim = 56"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RadjKACJy7q"
      },
      "source": [
        "generator = Sequential()\n",
        "\n",
        "generator.add(Dense(dim*dim*depth, input_dim=100 + classes))\n",
        "generator.add(BatchNormalization(momentum=0.9))\n",
        "generator.add(Activation('relu'))\n",
        "generator.add(Reshape((dim, dim, depth)))\n",
        "generator.add(Dropout(dropout))\n",
        "\n",
        "generator.add(UpSampling2D())\n",
        "generator.add(Conv2DTranspose(int(depth/2), 5, padding='same'))\n",
        "generator.add(BatchNormalization(momentum=0.9))\n",
        "generator.add(Activation('relu'))\n",
        "\n",
        "generator.add(UpSampling2D())\n",
        "generator.add(Conv2DTranspose(int(depth/4), 5, padding='same'))\n",
        "generator.add(BatchNormalization(momentum=0.9))\n",
        "generator.add(Activation('relu'))\n",
        "\n",
        "generator.add(Conv2DTranspose(3, 5, padding='same'))\n",
        "generator.add(Activation('sigmoid'))\n",
        "\n",
        "#generator.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-fzyRA-Jy-m"
      },
      "source": [
        "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "adversarial_model = Sequential()\n",
        "adversarial_model.add(generator)\n",
        "discriminator.trainable = False\n",
        "adversarial_model.add(discriminator)\n",
        "\n",
        "adversarial_model.compile(loss='categorical_crossentropy', \n",
        "                          optimizer=optimizer,\n",
        "                          metrics=['accuracy'])\n",
        "#adversarial_model.summary() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iL_k5jpeJksb"
      },
      "source": [
        "'''import numpy as np\n",
        "\n",
        "data_str=[]\n",
        "# Create a numpy array from a list of numbers\n",
        "arr = np.array(y_train)\n",
        "for i in range(10):\n",
        "  result = np.where(arr == i)\n",
        "  print(\"Elements with value 19 exists at following indices\", result[0], sep='\\n')\n",
        "  for j in result[0][0:10]:\n",
        "    data_str.append([x_train[j],i])\n",
        "\n",
        "np.save('jahid.npy',data_str)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEg4J2j9J7xd"
      },
      "source": [
        "import numpy as np\n",
        "x_train = np.load('/content/drive/MyDrive/Rice_Test/data1.npy', allow_pickle=True)\n",
        "y_train = np.load('/content/drive/MyDrive/Rice_Test/Healthy/data1_label.npy', allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElKay4YrJ706"
      },
      "source": [
        "def normalize(images):\n",
        "    images=images.astype('float32')\n",
        "    if images.max() > 1.0:\n",
        "        images/=255.0\n",
        "    return images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaEACb_nKJ8F"
      },
      "source": [
        "def one_hot(labels):\n",
        "    enc = OneHotEncoder()\n",
        "    return enc.fit_transform(y_train).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOkG9ogOKKDl"
      },
      "source": [
        "x_train = normalize(x_train)\n",
        "#y_train = one_hot(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTq61hwSKPPN"
      },
      "source": [
        "def create_generator_noise(batch_size):\n",
        "    noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
        "    sampling = np.random.randint(classes, size=batch_size)\n",
        "    noise_labels = np.zeros((batch_size, classes))\n",
        "    noise_labels[np.arange(batch_size), sampling] = 1\n",
        "    noise_input = np.concatenate((noise, noise_labels), axis=1)\n",
        "    \n",
        "    return noise_input, noise_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEkOGYe6KPR9"
      },
      "source": [
        "def create_generator_noise_by_label(labels):\n",
        "    noise = np.random.uniform(-1.0, 1.0, size=[len(labels), 100])\n",
        "\n",
        "    noise_labels = np.zeros((len(labels), classes))\n",
        "    noise_labels[np.arange(len(labels)), labels] = 1\n",
        "    noise_input = np.concatenate((noise, noise_labels), axis=1)\n",
        "    \n",
        "    return noise_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHGoTVfQKPVA"
      },
      "source": [
        "def train(batch_size=32, train_steps=10000):\n",
        "    discriminator_losses = []\n",
        "    adversarial_losses = []\n",
        "    sample_images = []\n",
        "    \n",
        "    for i in tnrange(train_steps):\n",
        "        # Select a random sample from the training data and the labels\n",
        "        sample_idx = np.random.randint(0, x_train.shape[0], size=batch_size)\n",
        "        images_train = x_train[sample_idx, :, :, :]\n",
        "        labels_train = y_train[sample_idx]\n",
        "        labels_train = np.concatenate((labels_train, np.zeros(shape=(batch_size, 1))), axis=1)\n",
        "        \n",
        "        # Create noise in range -1 to 1 and random labels as input for the generator to generate the fake images\n",
        "        noise_input, _ = create_generator_noise(batch_size)\n",
        "        images_fake = generator.predict(noise_input)\n",
        "        \n",
        "        # Create input by concatenate both real and fake images and assigning the respective labels\n",
        "        labels_fake = np.zeros(shape=(batch_size, classes+1))\n",
        "        labels_fake[:,-1] = 1\n",
        "        \n",
        "        input_data   = np.concatenate((images_train, images_fake))\n",
        "        input_labels = np.concatenate((labels_train, labels_fake))\n",
        "\n",
        "        discriminator_loss = discriminator_model.train_on_batch(input_data, input_labels)\n",
        "        \n",
        "        # Train the adversarial model to generate better images\n",
        "        noise_input, noise_labels = create_generator_noise(batch_size)\n",
        "        noise_labels = np.concatenate((noise_labels, np.zeros(shape=(batch_size, 1))), axis=1)\n",
        "        \n",
        "        adversarial_loss = adversarial_model.train_on_batch(noise_input, noise_labels)\n",
        "        \n",
        "        discriminator_losses.append(discriminator_loss)\n",
        "        adversarial_losses.append(adversarial_loss)\n",
        "        \n",
        "        if i % 100 == 0:\n",
        "            labels = [1]\n",
        "            noise = create_generator_noise_by_label(labels)\n",
        "            fake_images = generator.predict(noise)\n",
        "            sample_images.append(fake_images[0])\n",
        "    \n",
        "    return discriminator_losses, adversarial_losses, sample_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH-4dm-wJkvT"
      },
      "source": [
        "discriminator_losses, adversarial_losses, sample_images  = train(train_steps=10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRPxAQ1GJkyC"
      },
      "source": [
        "%%javascript\n",
        "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
        "    return false;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMa9eQ_BKlZ4"
      },
      "source": [
        "plt.figure(figsize=(20,40))\n",
        "for i, fake_image in enumerate(sample_images, 0):\n",
        "    plt.subplot(20, 10, i+1)\n",
        "    plt.imshow(np.reshape(fake_image, (img_cols, img_rows, channel)))\n",
        "    plt.title(\"Iteration %d\" % (i * 100))\n",
        "    plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJEoHexKKlch"
      },
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "\n",
        "plt.subplot(2,2,1)\n",
        "plt.plot(np.array(discriminator_losses)[:, 0])\n",
        "plt.title(\"Discriminator Losses\")\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(np.array(discriminator_losses)[:, 1])\n",
        "plt.title(\"Discriminator Accuracy\")\n",
        "\n",
        "plt.subplot(2,2,3)\n",
        "plt.plot(np.array(adversarial_losses)[:, 0], color='darkorange')\n",
        "plt.title(\"Adveserial Losses\")\n",
        "\n",
        "plt.subplot(2,2,4)\n",
        "plt.plot(np.array(adversarial_losses)[:, 1], color='darkorange')\n",
        "plt.title(\"Adveserial Accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UPM2LMrKljW"
      },
      "source": [
        "label_names = [\"healthy\", \"Brown_spot\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oph3uQKcKtvu"
      },
      "source": [
        "def sample_labels(size):\n",
        "    labels = []\n",
        "    for label, _ in enumerate(label_names):\n",
        "        for sample_size in range(size):\n",
        "            labels.append(label)\n",
        "    return labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV2cys9WKty7"
      },
      "source": [
        "fig, big_axes = plt.subplots(figsize=(20, 20) , nrows=len(label_names), ncols=1, sharey=True) \n",
        "\n",
        "for row, big_ax in enumerate(big_axes, start=1):\n",
        "    big_ax.set_title(label_names[row-1], fontsize=16)\n",
        "    big_ax.tick_params(labelcolor=(1.,1.,1., 0.0), top='off', bottom='off', left='off', right='off')\n",
        "    # removes the white frame\n",
        "    big_ax._frameon = False\n",
        "\n",
        "labels = sample_labels(15)\n",
        "noise = create_generator_noise_by_label(labels)\n",
        "\n",
        "fake_images = generator.predict(noise)\n",
        "\n",
        "plt.figure(figsize=(40,40))\n",
        "for i, fake_image in enumerate(fake_images, 1):\n",
        "    ax = fig.add_subplot(len(label_names), 15, i)\n",
        "    ax.imshow(np.reshape(fake_image, (img_cols, img_rows, channel)), cmap='gray')\n",
        "    ax.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}